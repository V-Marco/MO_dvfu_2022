{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "protected-imaging",
   "metadata": {},
   "source": [
    "## Логистическая регрессия и SVM\n",
    "\n",
    "#### План:\n",
    "1. Логистическая регрессия\n",
    "2. SVM.\n",
    "3. Ирисы Фишера. Свойства логистической регрессии и SVM\n",
    "4. Логистическая регрессия и SVM на менее приятных данных.\n",
    "5. ROC-кривая. \n",
    "6. Бонус: вывод логистической регрессии через правдоподобие\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-imperial",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-fortune",
   "metadata": {},
   "source": [
    "Напомним, что мы по-прежнему решаем задачу бинарной классификации, в которой целевая переменная $y$ принимает два значения: -1 и 1. На прошлом семинаре мы обсудили, что эту задачу можно решить при помощи линейного классификатора \n",
    "\n",
    "$$\n",
    "f(x_i, w) = \\mathrm{sign}\\left(\\langle x_i, w \\rangle\\right).\n",
    "$$\n",
    "\n",
    "Функция потерь для такой задачи – это сумма индикаторов того, что предсказание сделано неверно: \n",
    "\n",
    "$$Q(X, w) = \\frac{1}{\\ell}\\sum_{i = 1}^{\\ell}[y_i \\ne \\mathrm{sign}\\left(\\langle x_i, w \\rangle\\right)].$$\n",
    "\n",
    "На лекциях мы обсуждали, что эту идею можно удобно записать через функцию отступа:\n",
    "\n",
    "$$\n",
    "Q(X, w) = \\frac{1}{\\ell}\\sum_{i = 1}^{\\ell}[y_i \\langle x_i, w \\rangle < 0].\n",
    "$$\n",
    "\n",
    "Такую функцию проблематично дифференцировать по $w$, потому что даже в местах, где градиент существует, он равен нулю. Вместо этого будем минимизировать некоторую функцию $\\tilde{Q}(X, w)$, являющуюся верхней оценкой для $Q(X, w)$, и надеяться, что минимизация $\\tilde{Q}(X, w)$ позволит достаточно хорошо минимизировать и $Q(X, w)$.\n",
    "\n",
    "Логистическая регрессия предлагает использовать логистическую функцию потерь:\n",
    "\n",
    "$$\n",
    "\\tilde{Q}(X, w) = \\frac{1}{\\ell}\\sum_{i = 1}^{\\ell}\\log(1 + e^{-y_i \\langle x_i, w \\rangle}) \\rightarrow \\min_w.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exclusive-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "certified-dylan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.concatenate((np.linspace(-3, 0, 500), np.linspace(0, 3, 500)))\n",
    "np.random.seed(123)\n",
    "y = np.ones(1000)\n",
    "w = np.ones(1000)\n",
    "M = y * x * w\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(x * w, x < 0, label = \"$\\tilde{Q}(X, w)$, zero-one loss\")\n",
    "plt.plot(M, np.log2(1 + np.exp(-M)), label = \"$Q'(X, w)$, logistic loss\")\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-australian",
   "metadata": {},
   "source": [
    "Для получения классической задачи логистической регрессии остаётся сделать один шаг и немного изменить постановку задачи. Предположим, что мы хотим решать задачу **мягкой** классификации, то есть предсказывать не метку класса, а вероятность того, что наблюдение принадлежит к классу. Понятно, что мы всегда можем перейти от мягкой классификации к жёсткой, выбрав порог принадлежности к положительному классу. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-matrix",
   "metadata": {},
   "source": [
    "**Задание 1.** Поясните, почему для решения задачи мягкой классификации классификатор $f(x_i, w) = \\left(\\langle x_i, w \\rangle\\right)$ – не лучший выбор. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-lighting",
   "metadata": {},
   "source": [
    "**Ответ**\n",
    "\n",
    "Полученное скалярное произведение необязательно будет лежать в отрезке $[0, 1]$.\n",
    "\n",
    "Мы можем решить названную проблему, подставив $\\left(\\langle x_i, w \\rangle\\right)$ в некоторую функцию, областью значений которой является промежуток от 0 до 1. В логистической регрессии такой функцией выступает **сигмоида**:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\dfrac{e^x}{1 + e^x} = \\dfrac{1}{1 + e^{-x}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-apparel",
   "metadata": {},
   "source": [
    "**Задание 2.** Сигмоида обаладет замечательнеым свойством, которое значительно упрощает вычисление градиентов при градиентном спуске:\n",
    "\n",
    "$$\n",
    "\\sigma(x)'_x = \\sigma(x)(1 - \\sigma(x)). \n",
    "$$\n",
    "\n",
    "Покажите, что это действительно так.\n",
    "\n",
    "**Решение:**\n",
    "\n",
    "$$\n",
    "\\sigma(x)' = \\frac{e^x(1 + e^x) - e^{2x}}{(1 + e^x)^2} = \\frac{e^x}{1 + e^x}\\frac{1}{1 + e^x} = \\sigma(x)(1-\\sigma(x)).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-lounge",
   "metadata": {},
   "source": [
    "Путём хитрых математических преобразований можно показать, что при использовании сигмоиды (= при решении задачи мягкой классификации) $Q'(X, w)$ можно записать в следующем виде:\n",
    "\n",
    "$$\n",
    "Q'(X, w) = -\\frac{1}{\\ell} \\sum_{i=1}^{\\ell} [y_i = 1]\\log\\sigma(\\langle x_i, w \\rangle) + [y_i = -1](1 - \\log(\\sigma(\\langle x_i, w \\rangle))\n",
    "$$\n",
    "\n",
    "Эта функция называется log-loss или кросс-энтропией между истинной целевой переменной и предсказанными вероятностями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-planning",
   "metadata": {},
   "source": [
    "Регуляризация вводится таким же образом, как это было в случае линейной регрессии. Например, функция потерь для $l$-$2$ регуляризации выглядит так:\n",
    "\n",
    "$$\n",
    "\\bar{Q}'(X, w) = Q'(X, w) + \\frac{1}{2}\\lambda\\|w\\|^2_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-pricing",
   "metadata": {},
   "source": [
    "### Метод опорных векторов (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-cross",
   "metadata": {},
   "source": [
    "Метод опорных векторов – математически строго обоснованный метод, идея которого состоит в максимизации ширины разделяющей полосы между классами. Так как для подробного вывода SVM требуется уверенное владение методами квадратичной оптимизации, мы разберём только идею и практическую реализацию метода. \n",
    "\n",
    "Мы по-прежнему решаем задачу бинарной классификации и используем классификатор $f(x_i, w) = \\mathrm{sign}(\\langle x_i, w\\rangle)$. Предположим, что мы работаем с линейно разделимой выборкой. Мы хотим максимизировать отступ (расстояние от точки до разделяющей поверхности) классификатора:\n",
    "\n",
    "$$\n",
    "\\rho(x_i, \\langle x, w\\rangle) =  \\min_i\\dfrac{|{\\langle x_i, w\\rangle|}}{\\|w\\|}.\n",
    "$$\n",
    "\n",
    "Воспользуемся картинкой из Википедии, чтобы лучше понять эту идею:\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/1920px-SVM_margin.png\" alt=\"drawing\" width=\"400\"/>](https://en.wikipedia.org/wiki/Support-vector_machine#/media/File:SVM_margin.png)\n",
    "\n",
    "Заметим, что при делении $f(\\cdot)$ на положительное число ответы классификатора не меняются. Поделим $w$ нашего классификатора на $\\min_i |\\langle x_i, w \\rangle|$. Тогда отступ можно переписать как\n",
    "$$\n",
    "\\rho(\\langle x_i, w\\rangle) = \\frac{1}{\\|w\\|}.\n",
    "$$\n",
    "\n",
    "Получаем задачу SVM в линейно-разделимом случае:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\|w\\|^2 \\to \\min_{w}, \\\\\n",
    "y_i(\\langle x_i, w\\rangle) \\ge 1, \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Если выборка не является линейно-разделимой, то нам придётся позволить линейному классификатору допускать ошибки на некоторых наблюдениях. Тогда задача превращается в поиск оптимального выбора между максимизацией ширины разделяющей полосы и ошибок классификации:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\|w\\|^2 + C \\sum_{i = 1}^{\\ell} \\xi_i \\to \\min_{w, \\xi_i}, \\\\\n",
    "y_i(\\langle x_i, w\\rangle) \\ge 1 - \\xi_i, \\\\\n",
    "\\xi_i \\ge 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$C$ – параметр, который позволяет регулировать пропорции этого выбора. Чем больше $C$, тем больше штраф за неверную классификацию.\n",
    "\n",
    "[<img src=\"https://miro.medium.com/max/1400/1*0vOVPBmYCkw-sUt77HtyGA.png\" alt=\"drawing\" width=\"800\"/>](https://towardsdatascience.com/support-vector-machine-simply-explained-fee28eba5496)\n",
    "\n",
    "Путём хитрых математических преобразований можно показать, что итоговая функция потерь SVM выглядит следующим образом:\n",
    "\n",
    "$$\n",
    "Q(X, w) = C\\sum_{i=1}^{l} \\max\\{0, 1 - y_i(\\langle x_i, w\\rangle)\\} + \\|w\\|^2 \\to \\min_w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-sphere",
   "metadata": {},
   "source": [
    "### Ирисы Фишера. Свойства логистической регрессии и SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-worship",
   "metadata": {},
   "source": [
    "Рассмотрим свойства логистической регрессии и метода опорных векторов на примере классического набора данных [\"Ирисы Фишера\"](https://ru.wikipedia.org/wiki/Ирисы_Фишера). Этот набор состоит из 150 наблюдений, каждое из которых представляет собой четыре измерения: длина наружной доли околоцветника (`sepal length`), ширина наружной доли околоцветника (`sepal width`), длина внутренней доли околоцветника (`petal length`), ширина внутренней доли околоцветника (`petal width`). Каждое наблюдение относится к одному из трёх классов ириса: `setosa`, `versicolor` или `virginica`. Задача состоит в том, чтобы по измерениям предсказать класс цветка. \n",
    "\n",
    "[<img src=\"https://miro.medium.com/max/1000/1*Hh53mOF4Xy4eORjLilKOwA.png\" alt=\"drawing\" width=\"800\"/>](https://miro.medium.com/max/1000/1*Hh53mOF4Xy4eORjLilKOwA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collaborative-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "y = data['target']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-traveler",
   "metadata": {},
   "source": [
    "**Задание 1.** Перейдём к задаче бинарной классификации: будем предсказывать принадлежность цветка к виду `versicolor` против принадлежности ко всем прочим видам. Перекодируйте зависимую переменную так, чтобы цветки вида `versicolor` имели метку 1, а прочих видов – метку -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "broadband-bunch",
   "metadata": {},
   "source": [
    "**Задание 2**. Будем работать с двумя признаками: `sepal length (cm)` и `sepal width (cm)`. Отделите их в отдельную матрицу. Разделите выборку на обучающую и тестовую, долю тестовой выборки укажите равной 0.3. Отмасштабируйте выборки при помощи StandardScaler. Постройте диаграмму рассеяния по тренировочной выборке и убедитесь, что данные линейно не разделимы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "instant-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(123)\n",
    "\n",
    "X_train, y_train = #---<YOUR CODE HERE>--->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-intranet",
   "metadata": {},
   "source": [
    "**Задание 3.** Начнём с простого. Обучите логистическую регрессию и SVM с линейным ядром на тренировочной выборке и убедитесь, что полученные оценки весов действительно различаются. Убедитесь, что `accuracy`, возможно, не подходит в качестве метрики для данной задачи и рассчитайте `f1-меру` на тестовой выборке. Какой алгорим показал более высокое качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dense-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precious-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-prisoner",
   "metadata": {},
   "source": [
    "Теперь посмотрим, как различаются решающие поверхности алгоритмов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-disco",
   "metadata": {},
   "source": [
    "Код ниже построит решающие поверхности для классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "configured-label",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Filler values must be provided when X has more than 2 training features.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b963686570f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml_seminars/lib/python3.8/site-packages/mlxtend/plotting/decision_regions.py\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, clf, feature_index, filler_feature_values, filler_feature_ranges, ax, X_highlight, res, zoom_factor, legend, hide_spines, markers, colors, scatter_kwargs, contourf_kwargs, scatter_highlight_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfiller_feature_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             raise ValueError('Filler values must be provided when '\n\u001b[0m\u001b[1;32m    179\u001b[0m                              'X has more than 2 training features.')\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Filler values must be provided when X has more than 2 training features."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "labels = ['Logistic Regression', 'SVM']\n",
    "for clf, lab, grd in zip([lr, svm],\n",
    "                         labels,\n",
    "                         itertools.product([0, 1], repeat=2)):\n",
    "\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=np.array(X), y=np.array(y), clf=clf, legend=2)\n",
    "    plt.title(lab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-speaker",
   "metadata": {},
   "source": [
    "Теперь изучим свойства каждого классификатора по-отдельности. Начнём с логистической регрессии.\n",
    "\n",
    "**Задание 3.** Обучите три различные логистические регрессии с разным параметром регуляризации $\\alpha$ (обратите внимание, что в реализации `sklearn` $C = 1/\\alpha$). Как изменяется разделяющая поверхность в зависимости от $\\alpha$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "biological-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.1, 1, 1]\n",
    "\n",
    "lr1 = LogisticRegression()\n",
    "lr2 = LogisticRegression()\n",
    "lr3 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "placed-smith",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9d918ef73da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                          \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                          itertools.product([0, 1, 2], repeat=2)):\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "gs = gridspec.GridSpec(1, 3)\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "labels = ['C = ...', 'C = ...', 'C = ...']\n",
    "for clf, lab, grd in zip([lr1, lr2, lr3],\n",
    "                         labels,\n",
    "                         itertools.product([0, 1, 2], repeat=2)):\n",
    "    clf.fit(X_train, y_train)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X = X_train, y = np.array(y_train), clf=clf, legend=2)\n",
    "    plt.title(lab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-works",
   "metadata": {},
   "source": [
    "**Задание 4.** Теперь попробуем понять, что происходит при решении задачи мягкой классификации. Выведите выборочное среднее по целевой переменной тренировочной выборки. Используя метод `predict_proba()`, сделайте предсказание на тренировочной выборке. Сравните полученное среднее и предсказанную вероятность положительного класса. Как это можно объяснить? (подробный ответ в бонусной части в конце семинара). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-tiffany",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fitting-authority",
   "metadata": {},
   "source": [
    "Перейдём к SVM.\n",
    "\n",
    "**Задание 5.** Обучите три SVM с линейным ядром с разным параметром регуляризации $C$. Как изменяется разделяющая поверхность в зависимости от $C$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "continental-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = []\n",
    "\n",
    "svc1 =\n",
    "svc2 =\n",
    "svc3 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "collectible-education",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "gs = gridspec.GridSpec(1, 3)\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "labels = ['C = ...', 'C = ...', 'C = ...']\n",
    "for clf, lab, grd in zip([svc1, svc2, svc3],\n",
    "                         labels,\n",
    "                         itertools.product([0, 1, 2], repeat=2)):\n",
    "    clf.fit(X_train, y_train)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X = X_train, y = np.array(y_train), clf=clf, legend=2)\n",
    "    plt.title(lab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-queens",
   "metadata": {},
   "source": [
    "### Логистическая регрессия и SVM на менее приятных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-class",
   "metadata": {},
   "source": [
    "Мы будем работать с [набором данных](https://www.kaggle.com/piyushgoyal443/red-wine-dataset?select=wineQualityReds.csv), содержащим информацию о характеристиках вина. Каждое наблюдение принадлежит к одному из 10 категорий качества вина, и наша задача заключается в том, что предсказать эту категорию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "consecutive-shark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed.acidity  volatile.acidity  citric.acid  residual.sugar  chlorides  \\\n",
       "1            7.4              0.70         0.00             1.9      0.076   \n",
       "2            7.8              0.88         0.00             2.6      0.098   \n",
       "3            7.8              0.76         0.04             2.3      0.092   \n",
       "4           11.2              0.28         0.56             1.9      0.075   \n",
       "5            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free.sulfur.dioxide  total.sulfur.dioxide  density    pH  sulphates  \\\n",
       "1                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "2                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "3                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "4                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "5                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "1      9.4        5  \n",
       "2      9.8        5  \n",
       "3      9.8        5  \n",
       "4      9.8        6  \n",
       "5      9.4        5  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('wineQualityReds.csv', index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-memphis",
   "metadata": {},
   "source": [
    "Как указано в описании набора, в нём нет пропущенных значений, и все переменные являются непрерывными. Целевая переменная – `quality`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-paris",
   "metadata": {},
   "source": [
    "**Задание 1.** Перейдём к задаче бинарной классификации и будем предсказывать только наиболее популярную категорию качества. Закодируйте столбец `quality` так, чтобы наиболее частая категория (это категория 5) получила метку 1, а все прочие категории – метку -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-selection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "understanding-charity",
   "metadata": {},
   "source": [
    "**Задание 2.** Разделите признаки и целевую переменную. Разделите выборку на тренировочную и тестовую, долю тестовой выборки укажите равной 0.3. При помощи `StandardScaler` отмасштабируйте тренировочную и тестовую выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "tough-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-explorer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "built-moral",
   "metadata": {},
   "source": [
    "**Задание 3.** При помощи кросс-валидации (параметры выберите сами) подберите оптимальные значения коэффициентов регуляризации для логистической регрессии и SVM с линейным ядром. Обучите модели с этими параметрами. Убедитесь, что доля правильных ответов – не лучший вариант для нашей задачи и рассчитайте F-меру на тестовой выборке. Какой алгоритм показал себя лучше? \n",
    "\n",
    " **Бонус для самых отважных:** качество работы SVM можно улучшить за счёт применения ядер, после чего разделяющая поверхность становится нелинейной. Если вам интересно, попросите семинариста рассказать об этом подробнее.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "intense-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores_lr = []\n",
    "scores_svm = []\n",
    "\n",
    "for c in np.arange(0.1, 10, 1):\n",
    "    lr = LogisticRegression(C = c)\n",
    "    svm = SVC(C = c)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-census",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-convertible",
   "metadata": {},
   "source": [
    "### ROC-кривая"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-cliff",
   "metadata": {},
   "source": [
    "Ранее мы узнали, что помимо accuracy в задачах классификации так же используются precision, recall и f-мера. Теперь пришло время познакомиться с ещё одной метрикой – ROC AUC.\n",
    "\n",
    "Для начала вспомним, что мы работаем с матрицей ошибок:\n",
    "\n",
    "|       | alg = 1          | alg = -1    |\n",
    "|-------| -----------------|-------------|\n",
    "|y = 1  |TP                |FN           |\n",
    "|y = -1 |FP                | TN          |\n",
    "\n",
    "Определим следующие величины:\n",
    "\n",
    "$$\n",
    "TPR \\text{ (true positive rate, recall, sensitivity)} = \\dfrac{TP}{TP + FN} –\n",
    "$$\n",
    "доля правильно предсказанных объектов положительного класса.\n",
    "\n",
    "$$\n",
    "FPR \\text{ (false positive rate, 1 - specificity)} = \\dfrac{FP}{FP + TN} –\n",
    "$$\n",
    "доля неправильно предсказанных объектов отрицательного класса.\n",
    "\n",
    "Рассмотрим задачу мягкой классификации: мы предказываем вероятности принадлежности наблюдения к положительному и отрицательному классам. Тогда TPR и FPR будут зависеть от порога для вероятности, выше которого наблюдение будет отнесено к положительному классу. ROC-кривая строится в координатах $(FPR, TPR)$ и показывает комбинации TPR и FPR при всевозможных значениях порога. \n",
    "\n",
    "Для хорошего классификатора эта кривая является вогнутой, а для идеального классификатора она будет проходить через точку $(0, 1)$ (почему?).\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6b/Roccurves.png\" alt=\"drawing\" width=\"350\"/>](https://ru.wikipedia.org/wiki/ROC-кривая)\n",
    "\n",
    "\n",
    "\n",
    "**Задание 1.** Постройте ROC-кривую для следующей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True labels\n",
    "y = [-1, 1, 1, -1, 1, 1]\n",
    "# Predicted labels\n",
    "p = [0.5, 0.1, 0.2, 0.9, 0.7, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-adult",
   "metadata": {},
   "source": [
    "**Решение:**\n",
    "1. Упорядочим наблюдения по убыванию ответов алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [-1, 1, -1, 1, 1, 1]\n",
    "p = [0.9, 0.7, 0.5, 0.2, 0.1, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-strain",
   "metadata": {},
   "source": [
    "2. Разобьём единичный квадрат на $(m, n)$ частей, где $m$ – число 1 в $y$, $n$ – число нулей. Стартуем из точки $(0, 0)$. Если значение $y$ равно 1, делаем шаг вверх, а если -1 – вправо. Понятно, что конечная точка нашего маршрута – точка $(1, 1)$.\n",
    "\n",
    "**(Попросите семинариста нарисовать это)**. \n",
    "\n",
    "**Важный момент:** если у нескольких объектов значения предсказаний равны, а $y$ – различны, то мы должны сделать ход \"по диагонали\". \n",
    "\n",
    "**(Попросите семинариста нарисовать это)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-authorization",
   "metadata": {},
   "source": [
    "3. Полученная кривая и является ROC-кривой. \n",
    "\n",
    "**(Почему этот алгоритм имеет смысл?)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-princess",
   "metadata": {},
   "source": [
    "**Задание 2.** ROC AUC – площадь под ROC-кривой – равна доле пар наблюдений $(y = 1, y = -1)$, которые алгоритм верно упорядочил. Таким образом, чем больше ROC AUC, тем качественнее отработал классификатор. Вычислите ROC AUC для построенной ROC-кривой. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-spice",
   "metadata": {},
   "source": [
    "**Задание 3.** Как выглядит ROC-кривая для случайного классификатора? \n",
    "\n",
    "**Задание 4.** Как по ROC-кривой выбрать порог для бинаризации?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-blocking",
   "metadata": {},
   "source": [
    "В `sklearn` реализовано вычисление значений ROC-кривой и площади под ней. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "attached-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-credit",
   "metadata": {},
   "source": [
    "**Задание 5.** Постройте ROC-кривую и рассчитайте площадь под ней для логистической регрессии. О чём говорит такая форма кривой? Чтобы показать это, постройте pairplot данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "complex-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-drain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-accident",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "empirical-democracy",
   "metadata": {},
   "source": [
    "### Бонус для самых смелых: вывод логистической регрессии через правдоподобие\n",
    "\n",
    "Перекодируем $y$ так, что её возможные значения – это 0 и 1. Теперь $y$ является случайной величиной из распределения Бернулли. Тогда сигмоида задаёт условную вероятность принадлежности $y$ к положительному классу:\n",
    "\n",
    "$$\n",
    "P(y_i = 1 | x_i, w) = \\sigma(x_i, w).\n",
    "$$\n",
    "\n",
    "Будем оценку коэффициентов $w$ при помощи метода максимального правдоподобия.\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sigma(x_i, w)^{\\sum_i y_i}(1 - \\sigma(x_i, w))^{\\sum_i 1 - y_i}\n",
    "$$\n",
    "\n",
    "Логарифмируем:\n",
    "\n",
    "$$\n",
    "\\mathcal{l} = \\sum_i y_i \\log\\sigma(x_i, w) + (1 - y_i)(1 - \\log\\sigma(x_i, w))\n",
    "$$\n",
    "\n",
    "Если теперь взять среднее, то мы получим log-loss, взятый со знаком минус. Таким образом, минимизация функции потерь в логистической регрессии эквивалентна  максимизации правдоподобия в задаче нахождения оценок $w$!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
