{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение (ДВФУ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21c25e4f8bb31570029fd6b069131a5d00f84cf1"
   },
   "source": [
    "## Домашнее задание 2 (10 баллов)\n",
    "\n",
    "### Дедлайн: 19 марта, 23:59\n",
    "\n",
    "Домашнее задание состоит из двух частей. Каждая часть оценивается в 5 баллов, а все задания внутри одной части имеют одинаковый вес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Везде, где встречаются массивы или матрицы, подразумевается, что это `numpy.array`.\n",
    "\n",
    "2. Гуглите как можно больше! Если у вас появляется какой-то вопрос про использование метода numpy, скорее всего, на него уже есть ответ в Google – главное, правильно задать вопрос! Использование поисковика резко поощряется. \n",
    "\n",
    "3. Плагиат не допускается (нельзя просто так списать у друга). **НО:** можно использовать **любую** информацию из открытых Интернет-источников с указанием ссылки на них. Правила оформления из ДЗ 1 сохраняются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Часть 1: Pandas (5 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "568eb2d31004b87d22e119112ae01a1e75105f1d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных\n",
    "\n",
    "В папке Data находится информация о студентах. Всего 10 групп студентов. Файлы делятся на две категории:\n",
    "* Students_info_i - информация о студентах из группы i\n",
    "* Students_marks_i - оценки студентов из группы i за экзамены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одно из важных достоинств pandas $-$ это удобные методы реляционного взаимодействия с данными, аналогичные, например, возможностям SQL для слияния и конкатенации таблиц: merge, join, concat. Наличие готовых методов позволяет не реализовывать самостоятельно поэлементную обработку данных и оперировать сразу целыми таблицами данных.\n",
    "\n",
    "Подробно об этих методах посмотрите [вот тут](https://www.kaggle.com/residentmario/renaming-and-combining#Combining)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1:** Соберите всю информацию о студентах в одну таблицу df. В получившейся таблице должна быть информация и оценки всех студентов из всех групп. Напечатайте несколько строк таблицы для демонстрации результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8524af4cbd2f7b7810e8a3095a74c9fe1df7eafa"
   },
   "source": [
    "**Задание 2:** Удалите столбец index у полученной таблицы. Напечатайте первые 10 строк таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe62eee87b9b94ab923f57b55eaf0554612aa9e9"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5fcd622942b7ecfc318934c6a245d3bb3bf01e84"
   },
   "source": [
    "**Задание 3:** Выведите на экран размеры полученной таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16281cd7b4e941ebed8ca2e1b42f62f55d838684"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe8e3d58d29ca25dbbcf001392377643e6ff9a36"
   },
   "source": [
    "**Задание 4:** Выведите на экран статистические характеристики числовых столбцов таблицы (минимум, максимум, среднее значение, стандартное отклонение)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3d4bb80d2c4251fe517c24fcf08c5ff2d67b8aa"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b26b7de83485ecb3b8a0a7865a596e24527c7b2f"
   },
   "source": [
    "**Задание 5:** Проверьте, есть ли в таблице пропущенные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4eac3f8f83d07c6e58ad1576fe0e773f37034a2f"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6:** Выведите на экран средние баллы студентов по каждому предмету (math, reading, writing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7:** Как зависят оценки от того, проходил ли студент курс для подготовки к сдаче экзамена (test preparation course)? Выведите на экран для каждого предмета в отдельности средний балл студентов, проходивших курс для подготовки к экзамену и не проходивших курс.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8:** Выведите на экран все различные значения из столбца lunch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Зафиксируем минимальный балл для сдачи экзамена**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passmark = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9:** Ответьте на вопрос:\n",
    "* Какая доля женщин, не проходивших курс подготовки к экзамену, не сдала экзамен по математике? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 10:** С помощью groupby выполните задание ниже. Выведите время выполнения этого задания (подсказка: модуль `time`).\n",
    "\n",
    "* Для каждого уровня образования выведите минимальный балл за экзамен по письму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 11:** Выполните задание 10 с помощью циклов. Сравните время выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Часть 2: Градиентный спуск (5 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала давайте вспомним самый простой функционал ошибки, который мы применяем в задаче регрессии — Mean Squared Error:\n",
    "\n",
    "$$\n",
    "Q(w, X, y) = \\frac{1}{\\ell} \\sum\\limits_{i=1}^\\ell (\\langle x_i, w \\rangle - y_i)^2\n",
    "$$\n",
    "\n",
    "где $x_i$ — это $i$-ый объект датасета, $y_i$ — правильный ответ для $i$-го объекта, а $w$ — веса нашей линейной модели.\n",
    "\n",
    "Как мы помним, для линейной модели, его можно записать в матричном виде вот так:\n",
    "\n",
    "$$\n",
    "Q(w, X, y) = \\frac{1}{\\ell} || Xw - y ||^2\n",
    "$$\n",
    "\n",
    "где $X$ — это матрица объекты-признаки, а $y$ — вектор правильных ответов\n",
    "\n",
    "Для того чтобы воспользоваться методом градиентного спуска, нам нужно посчитать градиент нашего функционала. Для MSE он будет выглядеть так:\n",
    "\n",
    "$$\n",
    "\\nabla_w Q(w, X, y) = \\frac{2}{\\ell} X^T(Xw-y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведён базовый класс `BaseLoss`, который мы будем использовать для реализации всех наших лоссов. Менять его не нужно. У него есть два абстрактных метода:\n",
    "1. Метод `calc_loss`, который будет принимать на вход объекты `x`, правильные ответы `y` и веса `w` и вычислять значения лосса\n",
    "2. Метод `calc_grad`, который будет принимать на вход объекты `x`, правильные ответы `y` и веса `w` и вычислять значения градиента (вектор)\n",
    "\n",
    "**Примечание:** если вы не знакомы с реализацией в виде классов, ничего страшного! Все задания сводятся к реализации обычных питоновских функций!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class BaseLoss(abc.ABC):\n",
    "    \"\"\"Базовый класс лосса\"\"\"\n",
    "    @abc.abstractmethod\n",
    "    def calc_loss(self, X: np.ndarray, y: np.ndarray, w: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Функция для вычислений значения лосса\n",
    "        :param X: np.ndarray размера (n_objects, n_features) с объектами датасета\n",
    "        :param y: np.ndarray размера (n_objects,) с правильными ответами\n",
    "        :param w: np.ndarray размера (n_features,) с весами линейной регрессии\n",
    "        :return: число -- значения функции потерь\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def calc_grad(self, X: np.ndarray, y: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция для вычислений градиента лосса по весам w\n",
    "        :param X: np.ndarray размера (n_objects, n_features) с объектами датасета\n",
    "        :param y: np.ndarray размера (n_objects,) с правильными ответами\n",
    "        :param w: np.ndarray размера (n_features,) с весами линейной регрессии\n",
    "        :return: np.ndarray размера (n_features,) градиент функции потерь по весам w\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте напишем реализацию этого абстрактоного класса: Mean Squared Error лосс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 12:** Реализуйте класс `MSELoss`\n",
    "\n",
    "Он должен вычислять лосс и градиент по формулам сверху.\n",
    "\n",
    "**Подсказка:** функции внутри этого класса можно воспринимать и реализовывать как обычные функции! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss(BaseLoss):\n",
    "    def calc_loss(self, X: np.ndarray, y: np.ndarray, w: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Функция для вычислений значения лосса\n",
    "        :param X: np.ndarray размера (n_objects, n_features) с объектами датасета\n",
    "        :param y: np.ndarray размера (n_objects,) с правильными ответами\n",
    "        :param w: np.ndarray размера (n_features,) с весами линейной регрессии\n",
    "        :return: число -- значения функции потерь\n",
    "        \"\"\"\n",
    "        # -- YOUR CODE HERE --\n",
    "        # Вычислите значение функции потерь при помощи X, y и w и верните его\n",
    "        \n",
    "    def calc_grad(self, X: np.ndarray, y: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция для вычислений градиента лосса по весам w\n",
    "        :param X: np.ndarray размера (n_objects, n_features) с объектами датасета\n",
    "        :param y: np.ndarray размера (n_objects,) с правильными ответами\n",
    "        :param w: np.ndarray размера (n_features,) с весами линейной регрессии\n",
    "        :return: np.ndarray размера (n_features,) градиент функции потерь по весам w\n",
    "        \"\"\"\n",
    "        # -- YOUR CODE HERE --\n",
    "        # Вычислите значение вектора градиента при помощи X, y и w и верните его"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем создать объект `MSELoss` и при помощи него вычислять значение нашей функции потерь и градиенты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объект лосса\n",
    "loss = MSELoss()\n",
    "\n",
    "# Создадим какой-то датасет\n",
    "X = np.arange(200).reshape(20, 10)\n",
    "y = np.arange(20)\n",
    "\n",
    "# Создадим какой-то вектор весов\n",
    "w = np.arange(10)\n",
    "\n",
    "# Выведем значение лосса и градиента на этом датасете с этим вектором весов\n",
    "print(loss.calc_loss(X, y, w))\n",
    "print(loss.calc_grad(X, y, w))\n",
    "\n",
    "# Проверка, что методы реализованы правильно\n",
    "assert loss.calc_loss(X, y, w) == 27410283.5, \"Метод calc_loss реализован неверно\"\n",
    "assert np.allclose(loss.calc_grad(X, y, w), np.array([1163180., 1172281., 1181382., 1190483., \n",
    "                                                      1199584., 1208685., 1217786., 1226887., \n",
    "                                                      1235988., 1245089.])), \"Метод calc_grad реализован неверно\"\n",
    "print(\"Всё верно!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь когда у нас есть всё для вычисления градиента, давайте напишем наш градиентный спуск. Напомним, что формула для одной итерации градиентного спуска выглядит следующим образом:\n",
    "\n",
    "$$\n",
    "w^t = w^{t-1} - \\eta \\nabla_{w} Q(w^{t-1}, X, y)\n",
    "$$\n",
    "\n",
    "Где $w^t$ — значение вектора весов на $t$-ой итерации, а $\\eta$ — параметр learning rate, отвечающий за размер шага."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 13:** Реализуйте функцию `gradient_descent`\n",
    "\n",
    "Функция должна принимать на вход начальное значение весов линейной модели `w_init`, матрицу объектов-признаков `X`, \n",
    "вектор правильных ответов `y`, объект функции потерь `loss`, размер шага `lr` и количество итераций `n_iterations`.\n",
    "\n",
    "Функция должна реализовывать цикл, в котором происходит шаг градиентного спуска (градиенты берутся из `loss` посредством вызова метода `calc_grad`) по формуле выше и возвращать \n",
    "траекторию спуска (список из новых значений весов на каждом шаге)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(w_init: np.ndarray, X: np.ndarray, y: np.ndarray, \n",
    "                        loss: BaseLoss, lr: float, n_iterations: int = 100000) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Функция градиентного спуска\n",
    "    :param w_init: np.ndarray размера (n_feratures,) -- начальное значение вектора весов\n",
    "    :param X: np.ndarray размера (n_objects, n_features) -- матрица объекты-признаки\n",
    "    :param y: np.ndarray размера (n_objects,) -- вектор правильных ответов\n",
    "    :param loss: Объект подкласса BaseLoss, который умеет считать градиенты при помощи loss.calc_grad(X, y, w)\n",
    "    :param lr: float -- параметр величины шага, на который нужно домножать градиент\n",
    "    :param n_iterations: int -- сколько итераций делать\n",
    "    :return: Список из n_iterations объектов np.ndarray размера (n_features,) -- история весов на каждом шаге\n",
    "    \"\"\"\n",
    "    # -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим синтетический датасет и функцию, которая будет рисовать траекторию градиентного спуска по истории:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём датасет из двух переменных и реального вектора зависимости w_true\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "n_features = 2\n",
    "n_objects = 300\n",
    "batch_size = 10\n",
    "num_steps = 43\n",
    "\n",
    "w_true = np.random.normal(size=(n_features, ))\n",
    "\n",
    "X = np.random.uniform(-5, 5, (n_objects, n_features))\n",
    "X *= (np.arange(n_features) * 2 + 1)[np.newaxis, :]  \n",
    "y = X.dot(w_true) + np.random.normal(0, 1, (n_objects))\n",
    "w_init = np.random.uniform(-2, 2, (n_features))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSELoss()\n",
    "w_list = gradient_descent(w_init, X, y, loss, 0.01, 100)\n",
    "print(loss.calc_loss(X, y, w_list[0]))\n",
    "print(loss.calc_loss(X, y, w_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gd(w_list: Iterable, X: np.ndarray, y: np.ndarray, loss: BaseLoss):\n",
    "    \"\"\"\n",
    "    Функция для отрисовки траектории градиентного спуска\n",
    "    :param w_list: Список из объектов np.ndarray размера (n_features,) -- история весов на каждом шаге\n",
    "    :param X: np.ndarray размера (n_objects, n_features) -- матрица объекты-признаки\n",
    "    :param y: np.ndarray размера (n_objects,) -- вектор правильных ответов\n",
    "    :param loss: Объект подкласса BaseLoss, который умеет считать лосс при помощи loss.calc_loss(X, y, w)\n",
    "    \"\"\"\n",
    "    w_list = np.array(w_list)\n",
    "    meshgrid_space = np.linspace(-2, 2, 100)\n",
    "    A, B = np.meshgrid(meshgrid_space, meshgrid_space)\n",
    "\n",
    "    levels = np.empty_like(A)\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(A.shape[1]):\n",
    "            w_tmp = np.array([A[i, j], B[i, j]])\n",
    "            levels[i, j] = loss.calc_loss(X, y, w_tmp)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.title(\"GD trajectory\")\n",
    "    plt.xlabel(r'$w_1$')\n",
    "    plt.ylabel(r'$w_2$')\n",
    "    plt.xlim(w_list[:, 0].min() - 0.1, \n",
    "             w_list[:, 0].max() + 0.1)\n",
    "    plt.ylim(w_list[:, 1].min() - 0.1,\n",
    "             w_list[:, 1].max() + 0.1)\n",
    "    plt.gca().set_aspect('equal')\n",
    "\n",
    "    # visualize the level set\n",
    "    CS = plt.contour(A, B, levels, levels=np.logspace(0, 1, num=20), cmap=plt.cm.rainbow_r)\n",
    "    CB = plt.colorbar(CS, shrink=0.8, extend='both')\n",
    "\n",
    "    # visualize trajectory\n",
    "    plt.scatter(w_list[:, 0], w_list[:, 1])\n",
    "    plt.plot(w_list[:, 0], w_list[:, 1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 14:** При помощи функций `gradient_descent` и  `plot_gd` нарисуйте траекторию градиентного спуска для разных значений длины шага (параметра `lr`). Используйте не менее четырёх разных значений для `lr`. \n",
    "\n",
    "Сделайте и опишите свои выводы о том, как параметр `lr` влияет на поведение градиентного спуска\n",
    "\n",
    "Подсказки:\n",
    "* Функция `gradient_descent` возвращает историю весов, которую нужно подать в функцию `plot_gd`\n",
    "* Хорошие значения для `lr` могут лежать в промежутке от 0.0001 до 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
