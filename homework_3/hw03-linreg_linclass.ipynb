{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение (ДВФУ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 3 (10 баллов)\n",
    "\n",
    "### Дедлайн: 27 марта, 23:59\n",
    "\n",
    "Домашнее задание состоит из двух частей и бонусного задания. Каждая часть оценивается в 5 баллов, а все задания внутри одной части имеют одинаковый вес. За бонусное задание можно получить до трёх баллов, которые будут просуммированны с баллами за основное задание (то есть максимально за домашнее задание можно получить 13 баллов; баллы выше 10 так и пойдут в формулы оценок). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Везде, где встречаются массивы или матрицы, подразумевается, что это `numpy.array`.\n",
    "\n",
    "2. Гуглите как можно больше! Если у вас появляется какой-то вопрос про использование метода numpy, скорее всего, на него уже есть ответ в Google – главное, правильно задать вопрос! Использование поисковика резко поощряется. \n",
    "\n",
    "3. Плагиат не допускается (нельзя просто так списать у друга). **НО:** можно использовать **любую** информацию из открытых Интернет-источников с указанием ссылки на них. Правила оформления из ДЗ 1 сохраняются.\n",
    "\n",
    "4. Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Линейная регрессия (5 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы рассмотрим различные аспекты построения линейной модели. Мы будем работать с одним из классических наборов данных в статистике, содержащим информацию о бриллиантах. Описание можно посмотреть [здесь](https://www.kaggle.com/shivam2503/diamonds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 0:** Зарегистрируйтесь на kaggle и скачайте файл с данными `diamonds.csv`. Создайте в папке, в которой находится эта тетрадка, папку `data` и переместите скачанный файл в неё. Если всё сделано правильно, то код ниже прочтёт и сохранит в переменную `data` датафрейм с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z  \n",
       "0  2.43  \n",
       "1  2.31  \n",
       "2  2.31  \n",
       "3  2.63  \n",
       "4  2.75  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/diamonds.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем решать задачу предсказания цены бриллианта `price` в зависимости от его характеристик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1:** Есть ли в наборе данных пропущенные значения? Если да, удалите их. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2:** Есть ли в наборе данных бессмысленные столбцы (признаки, не несущие дополнительной информации)? Если да, то удалите их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3:** Линейная регрессия основана на предположении о линейной связи между признаками и целевой переменной, а потому перед выбором переменных для включения в модель имеет смысл проверить, насколько эта связь выполняется. Для следующих пунктов нам также потребуются выборочные корреляции между признаками. Выведите матрицу выборочных корреляций между всеми вещественными признаками и целевой переменной (то есть в этой матрице будет $k+1$ строка, где $k$ – количество вещественных признаков).\n",
    "\n",
    "Какие вещественные признаки коррелируют с целевой переменной больше всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4:** Так как линейная модель складывает значения признаков с некоторыми весами, нам нужно аккуратно обработать категориальные признаки. Закодируйте категориальные переменные при помощи OneHot-кодирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5:** Разделите выборку на тренировочную и тестовую. Долю тестовой выборки укажите равной 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6:** Зачастую при использовании линейных моделей вещественные признаки масштабируются. При этом оценки коэффициентов теряют прямую статистическую интерпретацию (\"при увеличении $X_1$ на 1, $y$ увеличивается на $w_1$\"), но приобретают свойства, полезные в задачах машинного обучения. В этой задаче масштабируйте вещественные признаки тренировочной и тестовой выборок при помощи модуля `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7:** Оцените линейную регрессию на тренировочной выборке. Выведите среднеквадратичную ошибку на тренировочной и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8:** Изучите документацию модуля `LinearRegression` и выведите полученные оценки коэффициентов. Назовите вещественные переменные, оценки коэффициентов которых по модулю на порядок превышают оценки прочих вещественных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9:** Как можно заметить из анализа корреляционной матрицы в задании 3, между некоторыми признаками имеется сильная корреляция, что может быть индикатором проблемы мультиколлинеарности. Различия в порядке коэффициентов, выявленные в предыдущей задаче также намекают на её присутствие. Как известно, для решения этой проблемы можно либо исключить некоторые признаки из модели, либо использовать регуляризацию. Мы воспользуемся вторым вариантом. \n",
    "\n",
    "Вспомним, что смысл регуляризации заключается в том, чтобы изменить функцию потерь так, чтобы устранить проблемы, появляющиеся из-за мультиколлинеарности. При L1-регуляризации предлагается минимизировать следующую функцию потерь:\n",
    "\n",
    "$$\n",
    "\\|y - X\\hat{w}\\|^2 + \\alpha\\sum_{i=1}^k|w_i|\n",
    "$$\n",
    "\n",
    "Такая модель называется Lasso-регрессией.\n",
    "\n",
    "При L2-регуляризации предлагается минимизировать следующую функцию потерь:\n",
    "\n",
    "$$\n",
    "\\|y - X\\hat{w}\\|^2 + \\frac{1}{2}\\alpha\\|w\\|^2\n",
    "$$\n",
    "\n",
    "Такая модель называется Ridge-регрессией. \n",
    "\n",
    "Обучите Lasso-регрессию и Ridge-регрессию, уставновив гиперпараметр регуляризации равным 10. Для этого используйте модули `Lasso` и `Ridge` из `sklearn`. Сильно ли уменьшились веса? Сделайте вывод о том, насколько сильно проблема мультиколлинеарности проявлялась в изначальной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 10:** Lasso-регрессию можно использовать для отбора наиболее информативных признаков. Для следующих значений параметра регуляриазции $\\alpha$: 0.1, 1, 10, 100, 200 –  обучите Lasso- и Ridge-регрессии и постройте график измненения евклидовой нормы весов (`np.linalg.norm()` от вектора оценок коэффициентов) в зависимости от параметра $\\alpha$. Как известно, норма является численной характеристикой величины вектора, а потому по норме можно судить о том, насколько большие элементы содержит вектор оценок коэффициентов. \n",
    "\n",
    "Какой метод агрессивнее уменьшает веса? Поясните, почему Lasso-регрессию часто используют для отбора признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 11:** \n",
    "В зависимости от значения параметра $\\alpha$ в Lasso-регрессии зануляются разные оценки коэффициентов. Оптимальное значение $\\alpha$ можно подобрать, например, при помощи кросс-валидации по тренировочной выборке. \n",
    "\n",
    "Для проведения кросс-валидации можно использовать модуль `LassoCV`. Этот модуль принимает список значений $\\alpha$ (параметр `alphas`) и при обучении проводит кросс-валидацию для каждого значения из этого списка, сохраняя MSE на каждом участке кросс-валидации (количество участков – параметр `cv`) в матрицу ошибок (то есть итоговая матрица будет иметь размер `len(alphas)` $\\times$ `cv`). После обучения модели матрицу ошибок можно получить, обратившись к атрибуту `.mse_path_`. \n",
    "\n",
    "Заметим, что модель может использовать $\\alpha$ не в том порядке, в котором вы подаёте их в функцию: для определения порядка используйте атрибут `.alphas_` Установите количество участков для кросс-валидации (параметр `cv`) равным 5.\n",
    "\n",
    "Усредните ошибки для каждого значения $\\alpha$ (то есть по строкам матрицы ошибок) и выберите то значение, которое даёт наибольшее качество. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Линейная классификация (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для наших экспериентов возьмём обучающую выборку [отсюда](https://www.kaggle.com/iabhishekofficial/mobile-price-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание $12-\\varepsilon$:** повторите шаги из задания 0 для новых данных `train.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решается задача многоклассовой классификации — определение ценовой категории телефона. Для простоты перейдём к задаче бинарной классификации — пусть исходные классы 0 и 1 соответствуют классу 0 новой целевой переменной, а остальные классу 1.\n",
    "\n",
    "**Задание 12:** Замените целевую переменную, отделите её в отдельную переменную и удалите из исходной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 13:** Разделите выборку на обучающую и тестовую части, долю тестовой части укажите равной 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части вы будете обучать самый простой бинарный классификатор — логистическую регрессию. Будем использовать готовую реализацию `LogisticRegression` из scikit-learn.\n",
    "\n",
    "Логистическая регрессия — линейный метод, то есть в нём предсказание алгоритма вычислаяется как скалярное произведение признаков и весов алгоритма: \n",
    "\n",
    "$$\n",
    "b(x) = w_0 + \\langle w, x \\rangle = w_0 + \\sum_{i=1}^{d} w_i x_i\n",
    "$$\n",
    "\n",
    "Для вычисления вероятности положительного класса применяется сигмода. В результате предсказание вероятности принадлежности объекта к положительному классу можно записать как: \n",
    "\n",
    "$$\n",
    "P(y = +1 | x) = \\frac{1}{1 + \\exp(- w_0 - \\langle w, x \\rangle )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забывайте, что для линейных методов матрицу объекты-признаки рекомендуется предварительно масштабировать (то есть привести каждый признак к одному и тому же масштабу одним из способов). Для этого можно воспользоваться `StandardScaler` или сделать это вручную."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 14:** Отмасштабируйте признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 15:** Обучите логистическую регрессию. Сделайте предсказания для тестовой части, посчитайте по ним AUC ROC и Accuracy (порог 0.5). Хорошо ли удаётся предсказывать целевую переменную?\n",
    "\n",
    "Не забывайте, что метод `predict_proba` вычисляет вероятности обоих классов выборки, а в бинарной классификации нас интересует в первую очередь вероятность принадлежности к положительному классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 16:** Постройте для обученной логистической регрессии ROC-кривую `roc_curve` и PR-кривую `precision_recall_curve`. Что можно сказать о качестве классификации в целом? Какой порог классификации оптимален?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусное задание: Обучение логистической регрессии (3 балла)\n",
    "\n",
    "Если выше вручную мы только применяли логистическую регрессию, то здесь предлагается реализовать обучение с помощью полного градиентного спуска.\n",
    "\n",
    "Если кратко, то обучение логистической регрессии с $L_2$-регуляризацией можно записать следующим образом:\n",
    "\n",
    "$$\n",
    "Q(w, X) = \\frac{1}{l} \\sum_{i=1}^{l} \\log (1 + \\exp(- y_i \\langle w, x_i \\rangle )) + \\frac{\\lambda_2}{2} \\lVert w \\rVert _2^2 \\to \\min_w\n",
    "$$\n",
    "\n",
    "Считаем, что $y_i \\in \\{-1, +1\\}$, а нулевым признаком сделан единичный (то есть $w_0$ соответствует свободному члену). Искать $w$ будем с помощью градиентного спуска:\n",
    "\n",
    "$$\n",
    "w^{(k+1)} = w^{(k)} - \\alpha \\nabla_w Q(w, X)\n",
    "$$\n",
    "\n",
    "В случае полного градиентного спуска $\\nabla_w Q(w, X)$ считается напрямую (как есть, то есть, используя все объекты выборки). Длину шага $\\alpha > 0$ в рамках данного задания предлагается брать равной некоторой малой константе.\n",
    "\n",
    "Градиент по объекту $x_i$ считается по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\nabla_w Q(w, x_i) = - \\frac{y_i x_i}{1 + \\exp(y_i \\langle w, x_i \\rangle)} + \\lambda_2 w\n",
    "$$\n",
    "\n",
    "На самом деле неправильно регуляризировать свободный член $w_0$ (то есть при добавлении градиента для $w_0$ не надо учитывать слагаемое с $\\lambda_2$). Но в рамках этого задания мы не обращаем на это внимания и работаем со всеми вектором весов одинаково. \n",
    "\n",
    "В качестве критерия останова необходимо использовать (одновременно):\n",
    "- проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$) — параметр tolerance\n",
    "- достижение максимального числа итераций (например, 10000) — параметр max\\_iter.\n",
    "\n",
    "Инициализировать веса можно случайным образом или нулевым вектором. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните **ровно один** из вариантов ниже (какой - без разницы, на баллы не влияет). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 1: брутальный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обучение логистической регрессии. Для удобства ниже предоставлен прототип с необходимыми методами. В `loss_history` необходимо сохранять вычисленное на каждой итерации значение функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LogReg(BaseEstimator):\n",
    "    def __init__(self, lambda_2=1.0, tolerance=1e-4, max_iter=1000, alpha=1e-3):\n",
    "        \"\"\"\n",
    "        lambda_2: L2 regularization param\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        alpha: learning rate\n",
    "        \"\"\"\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.loss_history = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        self.loss_history = []\n",
    "        \n",
    "        pass\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        ---\n",
    "        output: np.array of shape (l, 2) where\n",
    "        first column has probabilities of -1\n",
    "        second column has probabilities of +1\n",
    "        \"\"\"\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d) (l can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Примените логистическую регресиию на той же выборке.\n",
    "2. Посчитайте качество по тем же метрикам.\n",
    "3. Визуализируйте изменение значений функции потерь от номера итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка 1:** [видео](https://www.youtube.com/watch?v=Cx94tHmOuoA) и [статья с основами](https://python-scripts.com/object-oriented-programming-in-python) ООП.\n",
    "\n",
    "**Подсказка 2:** как и в предыдущем домашнем заднии, все функции внутри класса можно воспринимать как обычные функции, добавляется только взаимодействие между ними. Переменные и функции, заданные внутри класса, можно вызывать из любого места внутри класса, используя `self.`! Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleClass:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.x = 1 # Переменная x, созданная при инициализации класса\n",
    "        \n",
    "    def some_func(self):\n",
    "        print(self.x) # Обращаемся к x из другого места класса\n",
    "        \n",
    "    def other_func(self):\n",
    "        self.some_func() # Вызываем другую функцию этого класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка 3:** реализованный класс имеет ту же структуру методов, что и классы в sklearn, то есть пайплайн работы с ним такой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg()\n",
    "logreg.fit(..., ...)\n",
    "logreg.predict(..., ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 2: менее брутальный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм выше в виде отдельных функций. Задания те же.\n",
    "\n",
    "1. Примените логистическую регресиию на той же выборке.\n",
    "2. Посчитайте качество по тем же метрикам.\n",
    "3. Визуализируйте изменение значений функции потерь от номера итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, lambda_2=1.0, tolerance=1e-4, max_iter=1000, alpha=1e-3):\n",
    "    \"\"\"\n",
    "    X: np.array of shape (l, d)\n",
    "    y: np.array of shape (l)\n",
    "    lambda_2: L2 regularization param\n",
    "    tolerance: for stopping gradient descent\n",
    "    max_iter: maximum number of steps in gradient descent\n",
    "    alpha: learning rate\n",
    "    ---\n",
    "    output: w\n",
    "    \"\"\"\n",
    "    # code...\n",
    "    \n",
    "    w = ...\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(X, w):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ... # другие функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
